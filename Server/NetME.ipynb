{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bfSaVLRBX06",
        "outputId": "9d5999e8-1743-418b-e734-12886baf5020"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "sample_rate = 0.2\n",
        "n_threads = 2 # 4 #number of threads for data loader to use\n",
        "batchSize = 64 # 32 # 128\n",
        "nEpochs = 400 # 800\n",
        "learning_rate = 0.002 #0.0002\n",
        "beta1 = 0.5 # Adam momentum term\n",
        "nef = 64 # number of encoder filters in first conv layer\n",
        "imageSize = 32 # 64\n",
        "modelE_name = \"model_best.pth\"\n",
        "B_residual_block = 8 #8 \n",
        "train_size_p = 0.9\n",
        "val_size_p = 1-train_size_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLetZnq37zU-",
        "outputId": "83ce9571-61ac-44df-9634-a1a122245567"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "download = False\n",
        "train_set = datasets.CIFAR10(root='./data', train=True, download=download, transform=transform)\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=download, transform=transform)\n",
        "\n",
        "# Combine train and test sets\n",
        "full_dataset = torch.utils.data.ConcatDataset([train_set, test_set])\n",
        "subset = Subset(full_dataset, range(10000))\n",
        "\n",
        "# Split the dataset (90% training, 10% validation)\n",
        "train_size = int(train_size_p * len(subset))\n",
        "val_size = len(subset) - train_size\n",
        "train_dataset, val_dataset = random_split(subset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True, num_workers=n_threads)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batchSize, shuffle=False, num_workers=n_threads)\n",
        "\n",
        "print(\"CIFAR-10 dataset loaded successfully!\")\n",
        "print(f\"Number of training images: {len(train_dataset)}\")\n",
        "print(f\"Number of validation images: {len(val_dataset)}\")\n",
        "\n",
        "# Example: Access a batch\n",
        "images, labels = next(iter(train_loader))\n",
        "print(f\"Batch shape: {images.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "jwc_uv54GD1l",
        "outputId": "907481ab-66f2-4430-eb7b-c5a0b8fcfff6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Get a batch of images once (instead of inside the loop)\n",
        "batch = next(iter(train_loader))\n",
        "imgs, _ = batch  # Unpack images and labels\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow((imgs[i].permute(1,2,0) + 1.0) / 2.0)\n",
        "    plt.axis(\"off\")  # Hide axis for better visualization\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYwT3X4Dw7Qv"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "#import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torch\n",
        "\n",
        "\n",
        "class AttrProxy(object):\n",
        "    \"\"\"Translates index lookups into attribute lookups.\"\"\"\n",
        "    def __init__(self, module, prefix):\n",
        "        self.module = module\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return getattr(self.module, self.prefix + str(i))\n",
        "\n",
        "\n",
        "class NetE(nn.Module):\n",
        "    def __init__(self, nef):\n",
        "        super(NetE, self).__init__()\n",
        "        # state size: (nc) x 64 x 64\n",
        "        self.conv1 = nn.Conv2d(3, nef, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "        self.conv1_bn = nn.BatchNorm2d(nef)\n",
        "        self.conv1_relu = nn.LeakyReLU(0.2, inplace=False)\n",
        "        # state size: (nef) x 32 x 32\n",
        "        self.conv2 = nn.Conv2d(nef, nef*2, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "        self.conv2_bn = nn.BatchNorm2d(nef*2)\n",
        "        self.conv2_relu = nn.LeakyReLU(0.2, inplace=False)\n",
        "        # state size: (nef*2) x 16 x 16\n",
        "        self.conv3 = nn.Conv2d(nef*2, nef*4, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "        self.conv3_bn = nn.BatchNorm2d(nef*4)\n",
        "        self.conv3_relu = nn.LeakyReLU(0.2, inplace=False)\n",
        "        # state size: (nef*4) x 8 x 8\n",
        "        self.conv4 = nn.Conv2d(nef*4, nef*8, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "        self.conv4_bn = nn.BatchNorm2d(nef*8)\n",
        "        self.conv4_relu = nn.LeakyReLU(0.2, inplace=False)\n",
        "        # state size: (nef*8) x 4 x 4\n",
        "\n",
        "        # channel-wise fully connected layer\n",
        "        self.channel_wise_layers = []\n",
        "        fla = int(imageSize**2/256)\n",
        "        for i in range(0, 512):\n",
        "            self.add_module('channel_wise_layers_' + str(i), nn.Linear(fla, fla))\n",
        "\n",
        "        self.channel_wise_layers = AttrProxy(self, 'channel_wise_layers_')\n",
        "\n",
        "        # state size: (nef*8) x 4 x 4\n",
        "        self.dconv1 = nn.ConvTranspose2d(nef*8, nef*4, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "        self.dconv1_bn = nn.BatchNorm2d(nef*4)\n",
        "        self.dconv1_relu = nn.ReLU(inplace=True)\n",
        "        # state size: (nef*4) x 8 x 8\n",
        "        self.dconv2 = nn.ConvTranspose2d(nef*4, nef*2, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "        self.dconv2_bn = nn.BatchNorm2d(nef*2)\n",
        "        self.dconv2_relu = nn.ReLU(inplace=True)\n",
        "        # state size: (nef*2) x 16 x 16\n",
        "        self.dconv3 = nn.ConvTranspose2d(nef*2, nef, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "        self.dconv3_bn = nn.BatchNorm2d(nef)\n",
        "        self.dconv3_relu = nn.ReLU(inplace=True)\n",
        "        # state size: (nef) x 32 x 32\n",
        "        self.dconv4 = nn.ConvTranspose2d(nef, 3, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "        self.dconv4_tanh = nn.Tanh()\n",
        "        # self.dconv1_bn = nn.BatchNorm2d(3)\n",
        "        # state size: (nc) x 64 x 64\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_relu(self.conv1_bn(self.conv1(x)))\n",
        "        x = self.conv2_relu(self.conv2_bn(self.conv2(x)))\n",
        "        x = self.conv3_relu(self.conv3_bn(self.conv3(x)))\n",
        "        x = self.conv4_relu(self.conv4_bn(self.conv4(x)))\n",
        "\n",
        "        for i in range(0, 512):\n",
        "            slice_cur = x[:,[i],:,:]\n",
        "            slice_cur_size = slice_cur.size()\n",
        "            slice_cur = slice_cur.view(slice_cur_size[0], slice_cur_size[2]*slice_cur_size[3])\n",
        "            slice_cur = self.channel_wise_layers[i](slice_cur)\n",
        "            x[:,[i],:,:] = slice_cur.view(slice_cur_size[0], slice_cur_size[1], slice_cur_size[2], slice_cur_size[3])\n",
        "\n",
        "        x = self.dconv1_relu(self.dconv1_bn(self.dconv1(x)))\n",
        "        x = self.dconv2_relu(self.dconv2_bn(self.dconv2(x)))\n",
        "        x = self.dconv3_relu(self.dconv3_bn(self.dconv3(x)))\n",
        "        x = self.dconv4_tanh(self.dconv4(x))\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "\n",
        "        init.normal_(self.conv1_bn.weight,  1.0, 0.02)\n",
        "        init.normal_(self.conv2_bn.weight,  1.0, 0.02)\n",
        "        init.normal_(self.conv3_bn.weight,  1.0, 0.02)\n",
        "        init.normal_(self.conv4_bn.weight,  1.0, 0.02)\n",
        "        init.normal_(self.dconv1_bn.weight, 1.0, 0.02)\n",
        "        init.normal_(self.dconv2_bn.weight, 1.0, 0.02)\n",
        "        init.normal_(self.dconv3_bn.weight, 1.0, 0.02)\n",
        "\n",
        "        init.constant_(self.conv1_bn.bias,    0.0)\n",
        "        init.constant_(self.conv2_bn.bias,    0.0)\n",
        "        init.constant_(self.conv3_bn.bias,    0.0)\n",
        "        init.constant_(self.conv4_bn.bias,    0.0)\n",
        "        init.constant_(self.dconv1_bn.bias,   0.0)\n",
        "        init.constant_(self.dconv2_bn.bias,   0.0)\n",
        "        init.constant_(self.dconv3_bn.bias,   0.0)\n",
        "\n",
        "        init.normal_(self.conv1.weight,  0.0, 0.02)\n",
        "        init.normal_(self.conv2.weight,  0.0, 0.02)\n",
        "        init.normal_(self.conv3.weight,  0.0, 0.02)\n",
        "        init.normal_(self.conv4.weight,  0.0, 0.02)\n",
        "        init.normal_(self.dconv1.weight, 0.0, 0.02)\n",
        "        init.normal_(self.dconv2.weight, 0.0, 0.02)\n",
        "        init.normal_(self.dconv3.weight, 0.0, 0.02)\n",
        "        init.normal_(self.dconv4.weight, 0.0, 0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT42mfs_ERF9",
        "outputId": "57fa401c-85d9-4fa2-9693-67b2d987118b"
      },
      "outputs": [],
      "source": [
        "!pip install tensorboard_logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-OQPhyZlog_"
      },
      "outputs": [],
      "source": [
        "from tensorboard_logger import configure\n",
        "configure(\"tensorBoardRuns/on-demand-learn-p-02-zero-corrupt-0-conv-bias-0-cwfc-epoch-800\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz2Muqm3CCWk"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2UP1-cbCDwM",
        "outputId": "9ac69f4f-75dc-41c8-842e-96b55409f18d"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from math import log10\n",
        "#from tensorboard_logger import log_value\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "model = NetE(nef=64)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "print('===> Total Model NetE Parameters:', sum(param.numel() for param in model.parameters()))\n",
        "\n",
        "print('===> Initialize Optimizer...')\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
        "\n",
        "if not os.path.exists(\"epochs_NetE\"):\n",
        "        os.makedirs(\"epochs_NetE\")\n",
        "\n",
        "if not os.path.exists(\"tensorBoardRuns\"):\n",
        "        os.makedirs(\"tensorBoardRuns\")\n",
        "\n",
        "train_loss = []\n",
        "train_psnr = []\n",
        "val_loss = []\n",
        "val_psnr = []\n",
        "def train(epoch):\n",
        "    epoch_loss = 0\n",
        "    epoch_psnr = 0\n",
        "\n",
        "    #   Step up learning rate decay\n",
        "    lr = learning_rate\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "\n",
        "    for iteration, batch in tqdm(enumerate(train_loader, 1)):\n",
        "        target, _ = batch\n",
        "        batch_size = target.size(0)\n",
        "        image = target.clone()\n",
        "        #   Corrupt the target image\n",
        "        for i in range(0, batch_size):\n",
        "            corrupt_mask = np.random.binomial(1, (1 - sample_rate), (imageSize, imageSize))\n",
        "            corrupt_mask.astype(np.uint8)\n",
        "            #corrupt_mask = torch.ByteTensor(corrupt_mask)\n",
        "            corrupt_mask = torch.tensor(corrupt_mask, dtype=torch.bool)\n",
        "\n",
        "            image[i,0,:,:].masked_fill_(corrupt_mask, (0.0))\n",
        "            image[i,1,:,:].masked_fill_(corrupt_mask, (0.0))\n",
        "            image[i,2,:,:].masked_fill_(corrupt_mask, (0.0))\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion((model(image)+1.0)/2.0, (target+1.0)/2.0)\n",
        "        psnr = 10 * log10(1 / loss.item())\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_psnr += psnr\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"===> Epoch {} Complete: lr: {}, Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB\".format(epoch, lr, epoch_loss / len(train_loader), epoch_psnr / len(train_loader)))\n",
        "\n",
        "\n",
        "    #log_value('train_loss', epoch_loss / len(train_loader), epoch)\n",
        "    #log_value('train_psnr', epoch_psnr / len(train_loader), epoch)\n",
        "\n",
        "    train_loss.append(epoch_loss / len(train_loader))\n",
        "    train_psnr.append(epoch_psnr / len(train_loader))\n",
        "\n",
        "PSNR_best = 0\n",
        "\n",
        "def val(epoch):\n",
        "    avg_psnr = 0\n",
        "    avg_mse = 0\n",
        "    for batch in val_loader:\n",
        "        target, _ = batch\n",
        "        batch_size = target.size(0)\n",
        "        image = target.clone()\n",
        "        #   Corrupt the target image\n",
        "        for i in range(0, batch_size):\n",
        "            corrupt_mask = np.random.binomial(1, (1 - sample_rate), (imageSize, imageSize))\n",
        "            corrupt_mask.astype(np.uint8)\n",
        "            corrupt_mask = torch.tensor(corrupt_mask, dtype=torch.bool)\n",
        "\n",
        "            image[i,0,:,:].masked_fill_(corrupt_mask, (0.0))\n",
        "            image[i,1,:,:].masked_fill_(corrupt_mask, (0.0))\n",
        "            image[i,2,:,:].masked_fill_(corrupt_mask, (0.0))\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        prediction = model(image)\n",
        "        mse = criterion((prediction+1.0)/2.0, (target+1.0)/2.0)\n",
        "        psnr = 10 * log10(1 / mse.item())\n",
        "        avg_psnr += psnr\n",
        "        avg_mse  += mse.item()\n",
        "    print(\"===> Epoch {} Validation: Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB\".format(epoch, avg_mse / len(val_loader), avg_psnr / len(val_loader)))\n",
        "\n",
        "    #log_value('val_loss', avg_mse / len(val_loader), epoch)\n",
        "    #log_value('val_psnr', avg_psnr / len(val_loader), epoch)\n",
        "\n",
        "    val_loss.append(avg_mse / len(val_loader))\n",
        "    val_psnr.append(avg_psnr / len(val_loader))\n",
        "\n",
        "    global PSNR_best\n",
        "    if avg_psnr > PSNR_best:\n",
        "        PSNR_best = avg_psnr\n",
        "        model_out_path = \"epochs_NetE/\" + \"model_best.pth\".format(epoch)\n",
        "        torch.save(model, model_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(model_out_path))\n",
        "\n",
        "def checkpoint(epoch):\n",
        "    if epoch%100 == 0:\n",
        "        model_out_path = \"epochs_NetE/\" + \"model_epoch_{}.pth\".format(epoch)\n",
        "        torch.save(model, model_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(model_out_path))\n",
        "\n",
        "val(0)\n",
        "checkpoint(0)\n",
        "for epoch in range(1, nEpochs + 1):\n",
        "    train(epoch)\n",
        "    val(epoch)\n",
        "    checkpoint(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqdF-0WuKJ_T"
      },
      "source": [
        "## Trainign NetE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBa52sNk0I29",
        "outputId": "136d0044-075c-4e29-86da-37d732b58755"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if os.path.exists(\"epochs_NetE/\" + \"model_best.pth\"):\n",
        "    model = torch.load(\"epochs_NetE/\" + \"model_best.pth\")\n",
        "    print(\"Model loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDyWHinNQ2iJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(train_losses, val_losses,titre):\n",
        "\n",
        "    epochs = range(0, len(train_losses))\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Évolution de la \"+titre+\" au fil des Epochs\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l0Ep2hUUR1nG",
        "outputId": "4959425a-c176-4880-db56-49806cf3e3a5"
      },
      "outputs": [],
      "source": [
        "plot_loss(train_loss, val_loss[1:],\"loss\")\n",
        "plot_loss(train_psnr, val_psnr[1:],\"psnr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPsUyc2amo4J"
      },
      "source": [
        "# Test NetE on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1xap2qtMNcQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile\n",
        "\n",
        "# Load the image\n",
        "'''image_path = \"Eolienne.jpg\"\n",
        "\n",
        "# Open and preprocess the image\n",
        "original_image = Image.open(image_path).convert(\"RGB\")\n",
        "original_image = original_image.resize((imageSize, imageSize), Image.Resampling.LANCZOS)\n",
        "\n",
        "# Convert to numpy and normalize\n",
        "original_np = np.asarray(original_image, dtype=np.float32) / 255.0'''\n",
        "tensor,_ = val_dataset[np.random.randint(0,len(val_dataset)-1)]\n",
        "original_np = tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "# Convert to torch tensor and rearrange dimensions to (C, H, W)\n",
        "original_tensor = torch.tensor(original_np).permute(2, 0, 1).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Apply corruption mask\n",
        "corrupted_np = original_np.copy()\n",
        "corrupt_mask = np.random.binomial(1, (1 - sample_rate), (imageSize, imageSize)).astype(bool)\n",
        "\n",
        "# Apply mask to each channel\n",
        "for i in range(3):  # RGB channels\n",
        "    corrupted_np[:, :, i][corrupt_mask] = 0.0\n",
        "\n",
        "# Convert corrupted image to tensor\n",
        "corrupted_tensor = torch.tensor(corrupted_np).permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "# Move tensors to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "corrupted_tensor = corrupted_tensor.to(device)\n",
        "\n",
        "# Perform inference\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predicted_tensor = model(corrupted_tensor)\n",
        "    predicted_tensor = predicted_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()  # Convert back to (H, W, C)\n",
        "\n",
        "# Display results\n",
        "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "ax[0].imshow((original_np+1.0)/2.0)\n",
        "ax[0].set_title(\"Original Image\")\n",
        "ax[0].axis(\"off\")\n",
        "\n",
        "ax[1].imshow((corrupted_np+1.0)/2.0)\n",
        "ax[1].set_title(\"Corrupted Image\")\n",
        "ax[1].axis(\"off\")\n",
        "\n",
        "ax[2].imshow((predicted_tensor+1.0)/2.0)  # Clip values between 0-1\n",
        "ax[2].set_title(\"Predicted Image\")\n",
        "ax[2].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbX9OaiLC9tT"
      },
      "source": [
        "# NetM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU-8PLVIFWqu"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "#import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torch\n",
        "import math\n",
        "class Mean_Shift(nn.Module):\n",
        "    def __init__(self, sample_rate=0.2):\n",
        "        super(Mean_Shift, self).__init__()\n",
        "        self.sample_rate = sample_rate\n",
        "        self.sample_rate = torch.autograd.Variable(torch.tensor(sample_rate), requires_grad=False)\n",
        "        if torch.cuda.is_available(): self.sample_rate = self.sample_rate.cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()\n",
        "\n",
        "        x_mean = torch.mean(x, 2, True)\n",
        "        x_mean = torch.mean(x_mean, 3, True)\n",
        "        x_mean = x_mean.expand(x_size[0], x_size[1], x_size[2], x_size[3])\n",
        "\n",
        "        x_out = x / x_mean * self.sample_rate\n",
        "\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class _Residual_Block(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(_Residual_Block, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.in1 = nn.InstanceNorm2d(64, affine=True)\n",
        "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.in2 = nn.InstanceNorm2d(64, affine=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity_data = x\n",
        "        output = self.relu(self.in1(self.conv1(x)))\n",
        "        output = self.in2(self.conv2(output))\n",
        "        output = torch.add(output,identity_data)\n",
        "        return output\n",
        "\n",
        "\n",
        "class NetM(nn.Module):\n",
        "    def __init__(self, nef, sample_rate):\n",
        "        super(NetM, self).__init__()\n",
        "\n",
        "        self.conv_input = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, stride=1, padding=4, bias=False)\n",
        "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "        self.residual = self.make_layer(_Residual_Block, B_residual_block)\n",
        "\n",
        "        self.conv_mid = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn_mid = nn.InstanceNorm2d(64, affine=True)\n",
        "\n",
        "        self.conv_output = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=9, stride=1, padding=4, bias=False)\n",
        "        self.conv_output_bn = nn.BatchNorm2d(1)\n",
        "        self.conv_output_sig = nn.Sigmoid()\n",
        "\n",
        "        self.mean_shift = Mean_Shift(sample_rate=sample_rate)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def make_layer(self, block, num_of_layer):\n",
        "        layers = []\n",
        "        for _ in range(num_of_layer):\n",
        "            layers.append(block())\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.conv_input(x))\n",
        "        residual = out\n",
        "        out = self.residual(out)\n",
        "        out = self.bn_mid(self.conv_mid(out))\n",
        "        out = torch.add(out, residual)\n",
        "\n",
        "        out = self.conv_output_sig(self.conv_output_bn(self.conv_output(out)))\n",
        "        out = self.mean_shift(out)\n",
        "\n",
        "\t# iterative mean-clamp, to keep the sample rate precise\n",
        "        for i in range(0, 25):\n",
        "            #   Clip to [0, 1]\n",
        "            out = torch.clamp(out, min=0.0, max=1.0)\n",
        "            out = self.mean_shift(out)\n",
        "        out = torch.clamp(out, min=0.0, max=1.0)\n",
        "        return out\n",
        "\n",
        "class NetME(nn.Module):\n",
        "    def __init__(self, nef, NetE_name, sample_rate):\n",
        "        super(NetME, self).__init__()\n",
        "        self.netM  = NetM(nef = 64, sample_rate = sample_rate)\n",
        "        self.netE = NetE(nef = 64)\n",
        "        self.netE = torch.load(NetE_name, weights_only=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_clone = x.clone()\n",
        "        mask = self.netM(x)\n",
        "        mask_4d = mask.expand(mask.shape[0], 3, mask.shape[2], mask.shape[3])\n",
        "\n",
        "        mask_x = mask_4d * x_clone\n",
        "        x_recon = self.netE(mask_x)\n",
        "\n",
        "        return mask, x_recon\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHYdf2vOKLxv"
      },
      "source": [
        "train NETM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNM6VAZDNuWd",
        "outputId": "b575d046-2f15-4b8f-c4b4-d05e8ef0bf63"
      },
      "outputs": [],
      "source": [
        "#from tensorboard_logger import configure\n",
        "#print('===> Initialize Logger...')\n",
        "#configure(\"tensorBoardRuns/mask-train-conti-on-demand-learn-p-02-zero-corrupt-zero-conv-bias-conti-ber-train-v4-cwfc-one-net-eval-h5-val-sig-M-res_net-clip-mean-iter-switch-epoch-800\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "-eA-PcD_ONFH",
        "outputId": "4415fa2f-1a98-4ce4-ffdf-90d090666d9a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from math import log10\n",
        "#from tensorboard_logger import configure, log_value, log_images\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "import gc\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print('===> Building ME model...')\n",
        "modelME = NetME(nef = nef, NetE_name = 'epochs_NetE/' + modelE_name, sample_rate = sample_rate)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    modelME = modelME.cuda()\n",
        "modelME.netM.train()\n",
        "modelME.netE.eval()\n",
        "\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "print('===> Total Model NetME Parameters:', sum(param.numel() for param in modelME.parameters()))\n",
        "\n",
        "print('===> Initialize Optimizer...')\n",
        "optimizer = optim.Adam([{'params': modelME.netM.parameters(), 'lr': learning_rate},\n",
        "                        {'params': modelME.netE.parameters(), 'lr': 0.0}\n",
        "                        ], lr=learning_rate)\n",
        "\n",
        "if not os.path.exists(\"epochs_NetME\"):\n",
        "        os.makedirs(\"epochs_NetME\")\n",
        "\n",
        "if not os.path.exists(\"tensorBoardRuns\"):\n",
        "        os.makedirs(\"tensorBoardRuns\")\n",
        "\n",
        "val_loss = []\n",
        "val_psnr = []\n",
        "val_sparsity = []\n",
        "train_loss = []\n",
        "train_psnr = []\n",
        "train_sparsity = []\n",
        "\n",
        "def train(epoch):\n",
        "    epoch_loss = 0\n",
        "    epoch_psnr = 0\n",
        "    epoch_sparsity = 0\n",
        "\n",
        "    #\ttrain/eval modes make difference on batch normalization layer\n",
        "    modelME.netM.train()\n",
        "    modelME.netE.eval()\n",
        "\n",
        "    #   Step up learning rate decay\n",
        "    #   No learning rate decay here\n",
        "    #   Learning rate of NetE is fixed to be 0\n",
        "    #optimizer = optim.Adam([{'params': modelME.netM.parameters(), 'lr': learning_rate},\n",
        "                            #{'params': modelME.netE.parameters(), 'lr': 0.0}\n",
        "                            #], lr=learning_rate)\n",
        "\n",
        "    for iteration, batch in tqdm(enumerate(train_loader, 1)):\n",
        "        target, _ = batch\n",
        "        image = target.clone()\n",
        "\n",
        "        #\tmean_image and std_image are used to compute loss\n",
        "        mean_image = torch.zeros(image.shape[0], image.shape[1], image.shape[2], image.shape[3])\n",
        "        mean_image[:,0,:,:] = 0.5\n",
        "        mean_image[:,1,:,:] = 0.5\n",
        "        mean_image[:,2,:,:] = 0.5\n",
        "\n",
        "        std_image = torch.zeros(image.shape[0], image.shape[1], image.shape[2], image.shape[3])\n",
        "        std_image[:,0,:,:] = 0.5\n",
        "        std_image[:,1,:,:] = 0.5\n",
        "        std_image[:,2,:,:] = 0.5\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "            mean_image = mean_image.cuda()\n",
        "            std_image = std_image.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #   Generate the corruption mask and reconstructed image\n",
        "        corrupt_mask_conti, image_recon = modelME(image)\n",
        "\n",
        "        mask_sparsity = corrupt_mask_conti.sum() / (corrupt_mask_conti.shape[0] * corrupt_mask_conti.shape[1] * corrupt_mask_conti.shape[2] * corrupt_mask_conti.shape[3])\n",
        "\n",
        "        loss = criterion((image_recon*std_image)+mean_image, (target*std_image)+mean_image)\n",
        "        psnr = 10 * log10(1 / loss.item())\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_psnr += psnr\n",
        "        epoch_sparsity += mask_sparsity\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "     # 🚀 Explicitly delete unused tensors\n",
        "    del image, target, mean_image, std_image, corrupt_mask_conti, image_recon, loss\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    train_loss.append(epoch_loss / len(train_loader))\n",
        "    train_psnr.append(epoch_psnr / len(train_loader))\n",
        "    train_sparsity.append(epoch_sparsity.item() / len(train_loader))\n",
        "\n",
        "    print(\"===> Epoch {} Complete: lr: {}, Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Mask Sparsity: {:.4f}\".format(epoch, learning_rate, epoch_loss / len(train_loader), epoch_psnr / len(train_loader), epoch_sparsity / len(train_loader)))\n",
        "\n",
        "    #log_value('train_loss', epoch_loss / len(train_loader), epoch)\n",
        "    #log_value('train_psnr', epoch_psnr / len(train_loader), epoch)\n",
        "    #log_value('train_sparsity', epoch_sparsity / len(train_loader), epoch)\n",
        "\n",
        "PSNR_best = 0\n",
        "\n",
        "def reshape_4D_array(array_4D, width_num):\n",
        "    num, cha, height, width = array_4D.shape\n",
        "    height_num = ceil(float(num) / width_num)\n",
        "    total_width = width * width_num\n",
        "    total_height = height * height_num\n",
        "    target_array_4D = np.zeros((1, cha, total_height, total_width))\n",
        "    for index in range(0, num):\n",
        "        height_start = index//width_num\n",
        "        width_start = index%width_num\n",
        "        target_array_4D[:,:,height_start*height:height_start*height+height,width_start*width:width_start*width+width] = array_4D[index,:,:,:]\n",
        "    return target_array_4D\n",
        "\n",
        "def val(epoch):\n",
        "    avg_psnr = 0\n",
        "    avg_mse = 0\n",
        "    avg_sparsity = 0\n",
        "\n",
        "    modelME.eval()\n",
        "    modelME.netM.eval()\n",
        "    modelME.netE.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            target, _ = batch\n",
        "            image = target.clone()\n",
        "            image_clone = image.clone()\n",
        "\n",
        "            mean_image = torch.zeros(image.shape[0], image.shape[1], image.shape[2], image.shape[3])\n",
        "            mean_image[:,0,:,:] = 0.5\n",
        "            mean_image[:,1,:,:] = 0.5\n",
        "            mean_image[:,2,:,:] = 0.5\n",
        "\n",
        "            std_image = torch.zeros(image.shape[0], image.shape[1], image.shape[2], image.shape[3])\n",
        "            std_image[:,0,:,:] = 0.5\n",
        "            std_image[:,1,:,:] = 0.5\n",
        "            std_image[:,2,:,:] = 0.5\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                image = image.cuda()\n",
        "                image_clone = image_clone.cuda()\n",
        "                target = target.cuda()\n",
        "                mean_image = mean_image.cuda()\n",
        "                std_image = std_image.cuda()\n",
        "\n",
        "            #   Generate the corruption mask and reconstructed image\n",
        "            corrupt_mask_conti, _ = modelME(image)\n",
        "            \n",
        "            corrupt_mask = corrupt_mask_conti.bernoulli()   # Binarize the corruption mask using Bernoulli distribution, then feed into modelE\n",
        "            mask_sparsity = corrupt_mask.sum() / (corrupt_mask.shape[0] * corrupt_mask.shape[1] * corrupt_mask.shape[2] * corrupt_mask.shape[3])\n",
        "            corrupt_mask = corrupt_mask.expand(corrupt_mask.shape[0], 3, corrupt_mask.shape[2], corrupt_mask.shape[3])\n",
        "\n",
        "            #   Generate the corrupted image\n",
        "            mask_image = corrupt_mask * image_clone\n",
        "\n",
        "            restored_image = modelME.netE(mask_image)\n",
        "\n",
        "            mse = criterion((restored_image*std_image)+mean_image, (target*std_image)+mean_image)\n",
        "            psnr = 10 * log10(1 / mse.item())\n",
        "            avg_psnr += psnr\n",
        "            avg_mse  += mse.item()\n",
        "            avg_sparsity += mask_sparsity\n",
        "        # 🚀 Free up memory after validation\n",
        "        del image, target, mean_image, std_image, corrupt_mask_conti, mask_image, restored_image, mse\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    val_loss.append(avg_mse / len(val_loader))\n",
        "    val_psnr.append(avg_psnr / len(val_loader))\n",
        "    val_sparsity.append(avg_sparsity.item() / len(val_loader))\n",
        "\n",
        "\n",
        "    print(\"===> Epoch {} Validation: Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Mask Sparsity: {:.4f}\".format(epoch, avg_mse / len(val_loader), avg_psnr / len(val_loader), avg_sparsity / len(val_loader)))\n",
        "\n",
        "    #log_value('val_loss', avg_mse / len(val_loader), epoch)\n",
        "    #log_value('val_psnr', avg_psnr / len(val_loader), epoch)\n",
        "    #log_value('val_sparsity', avg_sparsity / len(val_loader), epoch)\n",
        "\n",
        "    #corrupt_mask_conti = corrupt_mask_conti.expand(corrupt_mask_conti.shape[0], 3, corrupt_mask_conti.shape[2], corrupt_mask_conti.shape[3])\n",
        "\n",
        "    # scipy.misc is DEPRECATED and has no attribute toimage\n",
        "    #log_images('original_image', reshape_4D_array((image*std_image+mean_image).cpu().numpy(), 10), step=1)\n",
        "    #log_images('conti_mask', reshape_4D_array(corrupt_mask_conti.data.cpu().numpy(), 10), step=1)\n",
        "    #log_images('binar_mask', reshape_4D_array(corrupt_mask.data.cpu().numpy(), 10), step=1)\n",
        "    #log_images('restored_image', reshape_4D_array((restored_image*std_image+mean_image).data.cpu().numpy(), 10), step=1)\n",
        "\n",
        "\n",
        "    global PSNR_best\n",
        "    if avg_psnr > PSNR_best:\n",
        "        PSNR_best = avg_psnr\n",
        "        model_out_path = \"epochs_NetME/\" + \"model_best.pth\"\n",
        "        torch.save(modelME.state_dict(), model_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(model_out_path))\n",
        "\n",
        "def val_rand(epoch):\n",
        "    avg_psnr = 0\n",
        "    avg_mse = 0\n",
        "    avg_sparsity = 0\n",
        "\n",
        "    modelME.eval()\n",
        "    modelME.netM.eval()\n",
        "    modelME.netE.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            target, _ = batch\n",
        "            image = target.clone()\n",
        "\n",
        "            mean_image = torch.zeros(image.shape[0], image.shape[1], image.shape[2], image.shape[3])\n",
        "            mean_image[:,0,:,:] = 0.5\n",
        "            mean_image[:,1,:,:] = 0.5\n",
        "            mean_image[:,2,:,:] = 0.5\n",
        "\n",
        "            std_image = torch.zeros(image.shape[0], image.shape[1], image.shape[2], image.shape[3])\n",
        "            std_image[:,0,:,:] = 0.5\n",
        "            std_image[:,1,:,:] = 0.5\n",
        "            std_image[:,2,:,:] = 0.5\n",
        "\n",
        "            #   Generate the random corruption mask\n",
        "            corrupt_mask = torch.ones(image.shape[0], 1, image.shape[2], image.shape[3])\n",
        "            corrupt_mask = corrupt_mask * sample_rate\n",
        "            mask_sparsity = corrupt_mask.sum() / (corrupt_mask.shape[0] * corrupt_mask.shape[1] * corrupt_mask.shape[2] * corrupt_mask.shape[3])\n",
        "            \n",
        "            corrupt_mask = corrupt_mask.bernoulli()\n",
        "            corrupt_mask = corrupt_mask.expand(corrupt_mask.shape[0], 3, corrupt_mask.shape[2], corrupt_mask.shape[3])\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                image = image.cuda()\n",
        "                target = target.cuda()\n",
        "                mean_image = mean_image.cuda()\n",
        "                std_image = std_image.cuda()\n",
        "                corrupt_mask = corrupt_mask.cuda()\n",
        "\n",
        "            #   Generate the corrupted image\n",
        "            mask_image = corrupt_mask * image\n",
        "\n",
        "            mse = criterion(( modelME.netE(mask_image)*std_image)+mean_image, (target*std_image)+mean_image)\n",
        "            psnr = 10 * log10(1 / mse.item())\n",
        "            avg_psnr += psnr\n",
        "            avg_mse  += mse.item()\n",
        "            avg_sparsity += mask_sparsity\n",
        "\n",
        "    print(\"===> Epoch {} Random Validation: Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Mask Sparsity: {:.4f}\".format(epoch, avg_mse / len(val_loader), avg_psnr / len(val_loader), avg_sparsity / len(val_loader)))\n",
        "\n",
        "    #log_value('val_loss_rand', avg_mse / len(val_loader), epoch)\n",
        "    #log_value('val_psnr_rand', avg_psnr / len(val_loader), epoch)\n",
        "    #log_value('val_sparsity_rand', avg_sparsity / len(val_loader), epoch)\n",
        "\n",
        "def checkpoint(epoch):\n",
        "    if epoch%100 == 0:\n",
        "        model_out_path = \"epochs_NetME/\" + \"model_epoch_{}.pth\".format(epoch)\n",
        "        torch.save(modelME.state_dict(), model_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(model_out_path))\n",
        "\n",
        "def cleanup_memory():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "val(0)\n",
        "val_rand(0)\n",
        "checkpoint(0)\n",
        "for epoch in range(1, nEpochs + 1):\n",
        "    train(epoch)\n",
        "    val(epoch)\n",
        "    val_rand(epoch)\n",
        "    checkpoint(epoch)\n",
        "\n",
        "    # 🚀 Call this after every epoch\n",
        "    cleanup_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"CUDA version:\", torch.version.cuda)\n",
        "print(\"CUDNN version:\", torch.backends.cudnn.version())\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "ADZL4kB5t3Di",
        "outputId": "95c29e79-59a2-46d1-a96c-1b2935725e6c"
      },
      "outputs": [],
      "source": [
        "plot_loss(train_loss, val_loss[1:],\"loss\")\n",
        "plot_loss(train_psnr, val_psnr[1:],\"psnr\")\n",
        "plot_loss(train_sparsity, val_sparsity[1:],\"sparsity\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT-dZwGvQ6Oy",
        "outputId": "528e356b-c154-419b-d91f-9d4310d03d7f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.path.exists(\"epochs_NetME/\" + \"model_best.pth\"):\n",
        "    modelME = NetME(nef = nef, NetE_name = 'epochs_NetE/' + modelE_name, sample_rate = sample_rate)\n",
        "    modelME.load_state_dict(torch.load(\"epochs_NetME/\" + \"model_best.pth\"))\n",
        "    print(\"Model loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile\n",
        "\n",
        "# Load the image\n",
        "tensor,_ = val_dataset[np.random.randint(0,len(val_dataset)-1)]\n",
        "original_np = tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "# Convert to torch tensor and rearrange dimensions to (C, H, W)\n",
        "image = torch.tensor(original_np).permute(2, 0, 1).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# convert to cuda\n",
        "if torch.cuda.is_available():\n",
        "    image = image.cuda()\n",
        "    modelME = modelME.cuda()\n",
        "\n",
        "\n",
        "# Generate the corruption mask and reconstructed image\n",
        "modelME.eval()\n",
        "modelME.netM.eval()\n",
        "modelME.netE.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "corrupt_mask_conti, _ = modelME(image)\n",
        "\n",
        "corrupt_mask = corrupt_mask_conti.bernoulli()   # Binarize the corruption mask using Bernoulli distribution, then feed into modelE\n",
        "\n",
        "corrupt_mask = corrupt_mask.expand(corrupt_mask.shape[0], 3, corrupt_mask.shape[2], corrupt_mask.shape[3])\n",
        "\n",
        "#   Generate the corrupted image\n",
        "mask_image = corrupt_mask * image\n",
        "\n",
        "restored_image = modelME.netE(mask_image)\n",
        "\n",
        "# Convert corrupted image to tensor\n",
        "corrupted_tensor = torch.tensor(mask_image).squeeze(0).permute(1, 2, 0).cpu().numpy()  # Convert back to (H, W, C)\n",
        "\n",
        "restored_image = restored_image.squeeze(0).permute(1, 2, 0).cpu().detach().numpy()  # Convert back to (H, W, C)\n",
        "\n",
        "# Display results\n",
        "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "ax[0].imshow((original_np+1.0)/2.0)\n",
        "ax[0].set_title(\"Original Image\")\n",
        "ax[0].axis(\"off\")\n",
        "\n",
        "ax[1].imshow((corrupted_tensor+1.0)/2.0)\n",
        "ax[1].set_title(\"Genrated mask Image\")\n",
        "ax[1].axis(\"off\")\n",
        "\n",
        "ax[2].imshow((restored_image+1.0)/2.0)  # Clip values between 0-1\n",
        "ax[2].set_title(\"Predicted Image\")\n",
        "ax[2].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile\n",
        "\n",
        "# Load the image\n",
        "tensor,_ = val_dataset[np.random.randint(0,len(val_dataset)-1)]\n",
        "original_np = tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "# Convert to torch tensor and rearrange dimensions to (C, H, W)\n",
        "image = torch.tensor(original_np).permute(2, 0, 1).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# convert to cuda\n",
        "if torch.cuda.is_available():\n",
        "    image = image.cuda()\n",
        "    modelME = modelME.cuda()\n",
        "\n",
        "\n",
        "# Generate the corruption mask and reconstructed image\n",
        "modelME.eval()\n",
        "modelME.netM.eval()\n",
        "modelME.netE.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "corrupt_mask_conti, _ = modelME(image)\n",
        "\n",
        "corrupt_mask = corrupt_mask_conti.bernoulli()   # Binarize the corruption mask using Bernoulli distribution, then feed into modelE\n",
        "corrupt_mask = corrupt_mask.expand(corrupt_mask.shape[0], 3, corrupt_mask.shape[2], corrupt_mask.shape[3])\n",
        "\n",
        "#   Generate the corrupted image\n",
        "mask_image = corrupt_mask * image\n",
        "\n",
        "restored_image = modelME.netE(mask_image)\n",
        "\n",
        "# Convert corrupted image to tensor\n",
        "corrupted_tensor = torch.tensor(mask_image).permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "restored_image = restored_image.squeeze(0).permute(1, 2, 0).cpu().numpy()  # Convert back to (H, W, C)\n",
        "\n",
        "# Display results\n",
        "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "ax[0].imshow((original_np+1.0)/2.0)\n",
        "ax[0].set_title(\"Original Image\")\n",
        "ax[0].axis(\"off\")\n",
        "\n",
        "ax[1].imshow((corrupted_tensor+1.0)/2.0)\n",
        "ax[1].set_title(\"Corrupted Image\")\n",
        "ax[1].axis(\"off\")\n",
        "\n",
        "ax[2].imshow((restored_image+1.0)/2.0)  # Clip values between 0-1\n",
        "ax[2].set_title(\"Predicted Image\")\n",
        "ax[2].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "_nJlCbI5uBb6",
        "outputId": "8d16ab15-766f-4edd-f177-6d6818fad3a3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile\n",
        "\n",
        "# Load the image\n",
        "tensor,_ = val_dataset[np.random.randint(0,len(val_dataset)-1)]\n",
        "original_np = tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "# Convert to torch tensor and rearrange dimensions to (C, H, W)\n",
        "image = torch.tensor(original_np).permute(2, 0, 1).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# convert to cuda\n",
        "if torch.cuda.is_available():\n",
        "    image = image.cuda()\n",
        "    modelME = modelME.cuda()\n",
        "\n",
        "\n",
        "# Generate the corruption mask and reconstructed image\n",
        "modelME.eval()\n",
        "modelME.netM.eval()\n",
        "modelME.netE.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "corrupt_mask_conti, _ = modelME(image)\n",
        "\n",
        "corrupt_mask = corrupt_mask_conti.bernoulli()   # Binarize the corruption mask using Bernoulli distribution, then feed into modelE\n",
        "corrupt_mask = corrupt_mask.expand(corrupt_mask.shape[0], 3, corrupt_mask.shape[2], corrupt_mask.shape[3])\n",
        "\n",
        "#   Generate the corrupted image\n",
        "mask_image = corrupt_mask * image\n",
        "\n",
        "restored_image = modelME.netE(mask_image)\n",
        "\n",
        "# Convert corrupted image to tensor\n",
        "corrupted_tensor = torch.tensor(mask_image).permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "restored_image = restored_image.squeeze(0).permute(1, 2, 0).cpu().numpy()  # Convert back to (H, W, C)\n",
        "\n",
        "# Display results\n",
        "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "ax[0].imshow((original_np+1.0)/2.0)\n",
        "ax[0].set_title(\"Original Image\")\n",
        "ax[0].axis(\"off\")\n",
        "\n",
        "ax[1].imshow((corrupted_tensor+1.0)/2.0)\n",
        "ax[1].set_title(\"Corrupted Image\")\n",
        "ax[1].axis(\"off\")\n",
        "\n",
        "ax[2].imshow((restored_image+1.0)/2.0)  # Clip values between 0-1\n",
        "ax[2].set_title(\"Predicted Image\")\n",
        "ax[2].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(mask_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI7IFdk3UL_g"
      },
      "outputs": [],
      "source": [
        "def reshape_4D_array(array_4D, width_num):\n",
        "    num, cha, height, width = array_4D.shape\n",
        "    height_num = num // width_num\n",
        "    total_width = width * width_num\n",
        "    total_height = height * height_num\n",
        "    target_array_4D = np.zeros((1, cha, total_height, total_width))\n",
        "    for index in range(0, num):\n",
        "        height_start = index // width_num\n",
        "        width_start = index % width_num\n",
        "        target_array_4D[:, :, height_start * height:height_start * height + height, width_start * width:width_start * width + width] = array_4D[index, :, :, :]\n",
        "    return target_array_4D\n",
        "\n",
        "def val(epoch):\n",
        "    avg_psnr = 0\n",
        "    avg_mse = 0\n",
        "    avg_sparsity = 0\n",
        "\n",
        "    modelME.eval()\n",
        "    modelME.netM.eval()\n",
        "    modelME.netE.eval()\n",
        "\n",
        "    for batch in val_loader:\n",
        "        target, _ = batch\n",
        "        image = target.clone()\n",
        "        image_clone = image.clone()\n",
        "\n",
        "        mean_image = torch.zeros(image.shape[0], image.shape[1], image.shape[2], image.shape[3])\n",
        "        mean_image[:,0,:,:] = 0.5\n",
        "        mean_image[:,1,:,:] = 0.5\n",
        "        mean_image[:,2,:,:] = 0.5\n",
        "\n",
        "        std_image = torch.zeros(image.shape[0], image.shape[1], image.shape[2], image.shape[3])\n",
        "        std_image[:,0,:,:] = 0.5\n",
        "        std_image[:,1,:,:] = 0.5\n",
        "        std_image[:,2,:,:] = 0.5\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            image_clone = image_clone.cuda()\n",
        "            target = target.cuda()\n",
        "            mean_image = mean_image.cuda()\n",
        "            std_image = std_image.cuda()\n",
        "\n",
        "        # Generate the corruption mask and reconstructed image\n",
        "        corrupt_mask_conti, _ = modelME(image)\n",
        "\n",
        "        corrupt_mask = corrupt_mask_conti.bernoulli()   # Binarize the corruption mask using Bernoulli distribution, then feed into modelE\n",
        "        mask_sparsity = corrupt_mask.sum() / (corrupt_mask.shape[0] * corrupt_mask.shape[1] * corrupt_mask.shape[2] * corrupt_mask.shape[3])\n",
        "        corrupt_mask = corrupt_mask.expand(corrupt_mask.shape[0], 3, corrupt_mask.shape[2], corrupt_mask.shape[3])\n",
        "\n",
        "        # Generate the corrupted image\n",
        "        mask_image = corrupt_mask * image_clone\n",
        "\n",
        "        restored_image = modelME.netE(mask_image)\n",
        "\n",
        "        mse = criterion((restored_image*std_image)+mean_image, (target*std_image)+mean_image)\n",
        "        psnr = 10 * log10(1 / mse.item())\n",
        "        avg_psnr += psnr\n",
        "        avg_mse  += mse.item()\n",
        "        avg_sparsity += mask_sparsity\n",
        "\n",
        "    print(\"===> Epoch {} Validation: Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Mask Sparsity: {:.4f}\".format(epoch, avg_mse / len(val_loader), avg_psnr / len(val_loader), avg_sparsity / len(val_loader)))\n",
        "\n",
        "    log_value('val_loss', avg_mse / len(val_loader), epoch)\n",
        "    log_value('val_psnr', avg_psnr / len(val_loader), epoch)\n",
        "    log_value('val_sparsity', avg_sparsity / len(val_loader), epoch)\n",
        "\n",
        "    corrupt_mask_conti = corrupt_mask_conti.expand(corrupt_mask_conti.shape[0], 3, corrupt_mask_conti.shape[2], corrupt_mask_conti.shape[3])\n",
        "\n",
        "    log_images('original_image', reshape_4D_array((image*std_image+mean_image).cpu().numpy(), 10), step=1)\n",
        "    log_images('conti_mask', reshape_4D_array(corrupt_mask_conti.data.cpu().numpy(), 10), step=1)\n",
        "    log_images('binar_mask', reshape_4D_array(corrupt_mask.data.cpu().numpy(), 10), step=1)\n",
        "    log_images('restored_image', reshape_4D_array((restored_image*std_image+mean_image).data.cpu().numpy(), 10), step=1)\n",
        "\n",
        "    global PSNR_best\n",
        "    if avg_psnr > PSNR_best:\n",
        "        PSNR_best = avg_psnr\n",
        "        model_out_path = \"epochs_NetME/\" + \"model_best.pth\"\n",
        "        torch.save(modelME.state_dict(), model_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(model_out_path))\n",
        "\n",
        "# Initialize global PSNR_best\n",
        "PSNR_best = 0\n",
        "\n",
        "# Run the validation function for one epoch with random data\n",
        "val(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPG8rSxI43jg",
        "outputId": "2e017e79-b9f2-4965-9bf0-a2ef1f69bf06"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "def reshape_4D_array(array_4D, width_num):\n",
        "    num, cha, height, width = array_4D.shape\n",
        "    height_num = ceil(num / width_num)\n",
        "    total_width = width * width_num\n",
        "    total_height = height * height_num\n",
        "    target_array_4D = np.zeros((1, cha, total_height, total_width))\n",
        "    for index in range(0, num):\n",
        "        height_start = index // width_num\n",
        "        width_start = index % width_num\n",
        "        target_array_4D[:, :, height_start * height:height_start * height + height, width_start * width:width_start * width + width] = array_4D[index, :, :, :]\n",
        "    return target_array_4D\n",
        "\n",
        "\n",
        "\n",
        "test = torch.zeros(3,3,64,64)\n",
        "reshape_4D_array(test,10).shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
